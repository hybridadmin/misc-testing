[default]
# PG18 data directory (PGDATA in the official Docker image)
pg1-path=/var/lib/postgresql/18/docker
pg1-user=postgres
pg1-port=5432

[global]
# Path where backups and archive are stored
repo1-path=/pgbackrest/pg2

# Store (full) backups for 60 days
repo1-retention-full-type=time
repo1-retention-full=60

# Differential backups only require full backups to be restored, so only keep a few of them
repo1-retention-diff=14

# S3 storage settings (rustfs)
repo1-type=s3
repo1-s3-bucket=pg-bucket
repo1-s3-key=rustfsadmin
repo1-s3-key-secret=rustfsadmin
repo1-s3-region=us-east-1
repo1-s3-uri-style=path
repo1-s3-endpoint=rustfs
repo1-storage-port=9000

# TLS: use the mkcert root CA to verify the rustfs server certificate
repo1-storage-verify-tls=y
repo1-storage-ca-file=/opt/cacert/rootCA.pem

# Force a checkpoint to start backup immediately.
start-fast=y

# Use delta restore.
delta=y

# Compress/upload in parallel. S3 uploads are not particularly CPU intensive so
# only ~40% of the below number of CPUs should actually be used.
process-max=8

# On main/offline dbs there can be a lot of WAL files in parallel, and S3
# upload is slow. So the default of synchronous uploads causes > 60s of lag
# meaning that backups start to fail. Setting to async minimizes the overhead
# of this so uploads are near-instant.
archive-async=y

# Increase archiving timeout to address the error:
# ERROR: [082]: unable to push WAL file '0000000100000F5A000000A0' to the archive asynchronously after 60 second(s)
archive-timeout=90

# Enable bz2 compression.
compress-type=bz2
compress-level=9

# Path where transient data will be stored when asynchronous archiving is enabled. Asynchronous archiving automatically confers
# some benefit by reducing the number of connections made to remote storage.
spool-path=/var/spool/pgbackrest

# S3 optimization to reduce number of files created
repo1-bundle=y

# Only store the changed blocks in backups in order to save space
repo1-block=y

# Logging settings
log-level-console=info
log-level-file=debug
